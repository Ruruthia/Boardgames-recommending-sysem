{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, reciprocal_rank, auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-harbor",
   "metadata": {},
   "source": [
    "### Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acquired-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../LightFM_ratings.csv.gz',  usecols=[1,2])\n",
    "# Nazwy najpopularniejszych kategorii\n",
    "features_names = pd.read_csv('../LightFM_item_features_names.csv.gz')\n",
    "# Kategorie konkretnych gier \n",
    "game_features = pd.read_csv('../LightFM_item_features.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greenhouse-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(by='bgg_user_name')\n",
    "cleaned_df = []\n",
    "for user, user_df in grouped:\n",
    "    if user_df.shape[0] < 10:\n",
    "        continue\n",
    "    cleaned_df.append(user_df[:])\n",
    "cleaned_df = pd.concat(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rough-mapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bgg_user_name\n",
       " mycroft           62\n",
       "- v -              12\n",
       "-=yod@=-          307\n",
       "-grizzly-          29\n",
       "-johnny-          125\n",
       "                 ... \n",
       "zzzxxxyyy          20\n",
       "zzzzz              37\n",
       "zzzzzane          169\n",
       "zzzzzyy            11\n",
       "æleksandr þræð     11\n",
       "Name: bgg_id, Length: 247376, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.groupby('bgg_user_name')['bgg_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "varying-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [x for x in features_names['0']]\n",
    "games_list = [x for x in cleaned_df['bgg_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "flexible-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the features of games for which we don't have any interaction\n",
    "game_features = game_features.drop((game_features['bgg_id'])[~game_features['bgg_id'].isin(games_list)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-restriction",
   "metadata": {},
   "source": [
    "### Preparation of interactions and item features matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "spatial-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.fit((x for x in cleaned_df['bgg_user_name']), (x for x in cleaned_df['bgg_id']), item_features=(x for x in features_names['0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "institutional-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Won't work with weird designers' names! (like \"..., Jr.\")\n",
    "item_features = dataset.build_item_features((val['bgg_id'], [w[1:-1].replace(\"\\\\'\", \"'\") for w in val['features'][1:-1].split(\", \") if w[1:-1].replace(\"\\\\'\", \"'\") in features_list]) for idx, val in game_features.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informed-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_interactions(df, dataset):\n",
    "    \n",
    "    def split_test(test_df, seed=42, frac=0.8):\n",
    "        grouped = test_df.groupby(by='bgg_user_name')\n",
    "        test_known = []\n",
    "        test_unknown = []\n",
    "        for user, df in grouped:\n",
    "            df_size = df.shape[0]\n",
    "            known_size = int(round(frac*df_size))\n",
    "            known_indices = np.random.choice(df_size, known_size, replace=False)\n",
    "            known_data = df.iloc[known_indices]\n",
    "            test_known.append(known_data)\n",
    "\n",
    "            unknown_indices = np.setdiff1d(np.arange(df_size), known_indices)\n",
    "            unknown_data = df.iloc[unknown_indices]\n",
    "            test_unknown.append(unknown_data)\n",
    "        return pd.concat(test_known), pd.concat(test_unknown)\n",
    "\n",
    "    users = df['bgg_user_name'].unique()\n",
    "    np.random.shuffle(users)\n",
    "    train_size = int(0.7*users.shape[0])\n",
    "    train_df = df[df['bgg_user_name'].isin(users[:train_size])]\n",
    "    test_df = df[df['bgg_user_name'].isin(users[train_size:])]\n",
    "    print('Splitting test set')\n",
    "    test_known, test_unknown = split_test(test_df)\n",
    "    interactions_df = train_df.append(test_known)\n",
    "    print('Preparing training interactions')\n",
    "    interactions = dataset.build_interactions(((val['bgg_user_name'], val['bgg_id']) for idx, val in interactions_df.iterrows()))\n",
    "    print('Preparing testing interactions')\n",
    "    test_interactions = dataset.build_interactions(((val['bgg_user_name'], val['bgg_id']) for idx, val in test_unknown.iterrows()))\n",
    "    return interactions[0], test_interactions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dated-blade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting test set\n",
      "Preparing training interactions\n",
      "Preparing testing interactions\n"
     ]
    }
   ],
   "source": [
    "interactions, test_interactions = prepare_interactions(cleaned_df, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-client",
   "metadata": {},
   "source": [
    "### WARP loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caroline-stanley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f3a08ad96a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp')\n",
    "model.fit(interactions, verbose=True, epochs=20, num_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "concrete-bhutan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.41\n",
      "Precision: test 0.15\n"
     ]
    }
   ],
   "source": [
    "train_precision = precision_at_k(model, interactions, k=10, num_threads=8).mean()\n",
    "print('Precision: train %.2f' % (train_precision))\n",
    "\n",
    "test_precision = precision_at_k(model, test_interactions, train_interactions = interactions, k=10, num_threads=8).mean()\n",
    "print('Precision: test %.2f' % (test_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-synthesis",
   "metadata": {},
   "source": [
    "### BPR loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sudden-dispute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f3a08adf430>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_model = LightFM(loss='bpr')\n",
    "bpr_model.fit(interactions, verbose=True, epochs=20, num_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "appointed-mitchell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.37\n",
      "Precision: test 0.10\n"
     ]
    }
   ],
   "source": [
    "train_precision = precision_at_k(bpr_model, interactions, k=10, num_threads=8).mean()\n",
    "print('Precision: train %.2f' % (train_precision))\n",
    "\n",
    "test_precision = precision_at_k(bpr_model, test_interactions, train_interactions = interactions, k=10, num_threads=8).mean()\n",
    "print('Precision: test %.2f' % (test_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-reach",
   "metadata": {},
   "source": [
    "### BPR loss with item features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "introductory-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fcedb090e80>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr_model = LightFM(loss='warp', no_components = 64, item_alpha = 1e-6)\n",
    "bpr_model.fit(interactions, verbose=True, item_features = item_features, epochs=20, num_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision = precision_at_k(bpr_model, interactions, item_features = item_features, k=10, num_threads=8).mean()\n",
    "print('Precision: train %.2f' % (train_precision))\n",
    "\n",
    "test_precision = precision_at_k(bpr_model, test_interactions, train_interactions = interactions, item_features = item_features, k=10, num_threads=8).mean()\n",
    "print('Precision: test %.2f' % (test_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-american",
   "metadata": {},
   "source": [
    "### Additional evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall = recall_at_k(model, interactions, k=10, num_threads=8).mean()\n",
    "print('Recall: train %.2f' % (train_recall))\n",
    "\n",
    "test_recall = recall_at_k(model, test_interactions, train_interactions = interactions, k=10, num_threads=8).mean()\n",
    "print('Recall: test %.2f' % (test_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc = auc_score(model, interactions, num_threads=8).mean()\n",
    "print('AUC: train %.2f' % (train_auc))\n",
    "\n",
    "test_auc = auc_score(model, test_interactions, train_interactions = interactions, num_threads=8).mean()\n",
    "print('AUC: test %.2f' % (test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recip = reciprocal_rank(model, interactions, num_threads=8).mean()\n",
    "print('Reciprocal rank: train %.2f' % (train_recip))\n",
    "\n",
    "test_recip = reciprocal_rank(model, test_interactions, train_interactions = interactions, num_threads=8).mean()\n",
    "print('Reciprocal rank: test %.2f' % (test_recip))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
